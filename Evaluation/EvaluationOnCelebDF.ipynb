{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c38dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import random\n",
    "import zipfile\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from functools import reduce\n",
    "import torch.nn as nn\n",
    "from einops import rearrange, repeat\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.transforms import ToPILImage\n",
    "# from linformer import Linformer\n",
    "from PIL import Image\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "# from vit_pytorch.efficient import ViT\n",
    "# from model import BiSeNet\n",
    "import torchvision.transforms as transforms\n",
    "from skimage import io, img_as_float\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62df40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 17\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6631b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir_real = '../Datasets/DeepfakeDetection/FakeAVCeleb_v1_2/Cleaned_Data/Images/test_set_real/'\n",
    "test_dir_fake = '../Datasets/DeepfakeDetection/FakeAVCeleb_v1_2/Cleaned_Data/Images/test_set_D_fake/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d6fa774",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7547593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "models = ['xception', 'res2net101_26w_4s', 'tf_efficientnet_b7_ns', 'vit_base_patch16_224', 'swin_base_patch4_window7_224', 'mvitv2_base']\n",
    "# augs = ['No_Augmentations', 'Random_Cut_Out_Augs', 'Face_Cut_Out_Augs']\n",
    "datasets = ['FakeAVCeleb', 'FaceForensics', 'DFDC', 'ForgeryNet']\n",
    "model_name = models[5]\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9841a11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiScaleVit(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "  )\n",
       "  (stages): ModuleList(\n",
       "    (0): MultiScaleVitStage(\n",
       "      (blocks): ModuleList(\n",
       "        (0): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): MultiScaleVitStage(\n",
       "      (blocks): ModuleList(\n",
       "        (0): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (shortcut_proj_attn): Linear(in_features=96, out_features=192, bias=True)\n",
       "          (shortcut_pool_attn): MaxPool2d(kernel_size=[3, 3], stride=(2, 2), padding=[1, 1], dilation=1, ceil_mode=False)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=96, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (2): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): MultiScaleVitStage(\n",
       "      (blocks): ModuleList(\n",
       "        (0): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (shortcut_proj_attn): Linear(in_features=192, out_features=384, bias=True)\n",
       "          (shortcut_pool_attn): MaxPool2d(kernel_size=[3, 3], stride=(2, 2), padding=[1, 1], dilation=1, ceil_mode=False)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (2): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (3): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (4): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (5): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (6): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (7): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (8): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (9): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (10): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (11): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (12): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (13): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (14): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (15): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): MultiScaleVitStage(\n",
       "      (blocks): ModuleList(\n",
       "        (0): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (shortcut_proj_attn): Linear(in_features=384, out_features=768, bias=True)\n",
       "          (shortcut_pool_attn): MaxPool2d(kernel_size=[3, 3], stride=(2, 2), padding=[1, 1], dilation=1, ceil_mode=False)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (2): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Sequential(\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../model_weights/supervised_models/mvitv2_base/Random_Cut_Out_Augs/DFDC/3_epochs.pth'\n",
    "\n",
    "model.load_state_dict(torch.load(PATH), strict=True)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d7e152",
   "metadata": {},
   "source": [
    "# Evaluate on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b89e35ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos = sorted(glob.glob('../Datasets/DeepfakeDetection/Celeb-DF-v2/Cleaned_Data/Images/test_set_real/*/'))\n",
    "videos = [path.replace('\\\\','/') for path in videos]\n",
    "len(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80c3751e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "labels_map = [\"fake\", \"real\"]\n",
    "count = 0\n",
    "predictions = {}\n",
    "probs = {}\n",
    "for vid in videos:\n",
    "    count+=1\n",
    "    print(count)\n",
    "    fake_prob = 0\n",
    "    real_prob = 0\n",
    "#     print(vid)\n",
    "    images = sorted(glob.glob('../Datasets/DeepfakeDetection/Celeb-DF-v2/Cleaned_Data/Images/test_set_real/'+str(vid.split('/')[-2])+'/*.png'))\n",
    "    images = [path.replace('\\\\','/') for path in images]\n",
    "    if len(images) >= 16:\n",
    "        for image in images[:16]:\n",
    "            img = Image.open(image)\n",
    "            tfms = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                                      ])\n",
    "            img = tfms(img)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(img.unsqueeze(0).to(device))\n",
    "            for idx in torch.topk(outputs[0], k=1).indices.tolist():\n",
    "                prob = torch.softmax(outputs[0], 0)[idx].item()\n",
    "                if labels_map[idx] == 'fake':\n",
    "                    fake_prob += prob\n",
    "                    real_prob += 1-prob\n",
    "                else:\n",
    "                    real_prob += prob\n",
    "                    fake_prob += 1 - prob\n",
    "        if real_prob > fake_prob:\n",
    "            predictions[vid.split('/')[-2]] = [(real_prob/len(images[:16])), 1, 1]\n",
    "            probs[vid.split('/')[-2]] = (real_prob/len(images[:16]))\n",
    "#             print(image)\n",
    "            print('real', real_prob/len(images[:16]))\n",
    "        else:\n",
    "            predictions[vid.split('/')[-2]] = [1-(fake_prob/len(images[:16])), 0, 1]\n",
    "            probs[vid.split('/')[-2]] = 1-(fake_prob/len(images[:16]))\n",
    "            print(image)\n",
    "            print('fake', fake_prob/len(images[:16]))\n",
    "    else:\n",
    "        print(\"Less than 16 frames in: \", vid)\n",
    "    print('--------------')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7c444f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "originallabel = 'REAL'\n",
    "# originallabel = 'FAKE'\n",
    "\n",
    "folder_path = ('TestScores/Image/celebdf/with_augs/')\n",
    "with open(folder_path + model_name + '_' + 'results' + '_' + originallabel + '.csv', 'w') as csvfile:\n",
    "    fieldnames = ['Video', 'ProbabilityScore', 'PredictedLabel', 'OriginalLabel']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, lineterminator='\\n',)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for i in range(len(predictions)):\n",
    "        vid = list(predictions)[i]\n",
    "        writer.writerow({'Video': list(predictions)[i], 'ProbabilityScore': predictions[vid][0], 'PredictedLabel': predictions[vid][1], 'OriginalLabel': predictions[vid][2]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ac313bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos = sorted(glob.glob('../Datasets/DeepfakeDetection/Celeb-DF-v2/Cleaned_Data/Images/test_set_fake/*/'))\n",
    "videos = [path.replace('\\\\','/') for path in videos]\n",
    "\n",
    "len(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66cb4bff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
  
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "labels_map = [\"fake\", \"real\"]\n",
    "count = 0\n",
    "predictions = {}\n",
    "probs = {}\n",
    "for vid in videos:\n",
    "    count+=1\n",
    "    print(count)\n",
    "    fake_prob = 0\n",
    "    real_prob = 0\n",
    "#     print(vid)\n",
    "    images = sorted(glob.glob('../Datasets/DeepfakeDetection/DFDC/Cleaned_Data/Images/test_set_real/'+str(vid.split('/')[-2])+'/*.png'))\n",
    "    images = [path.replace('\\\\','/') for path in images]\n",
    "    if len(images) >= 12:\n",
    "        for image in images:\n",
    "            img = Image.open(image)\n",
    "            tfms = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                                      ])\n",
    "            img = tfms(img)\n",
    "            with torch.no_grad():\n",
    "                outputs = net(img.unsqueeze(0).to(device))\n",
    "            for idx in torch.topk(outputs[0], k=1).indices.tolist():\n",
    "                prob = torch.softmax(outputs[0], 0)[idx].item()\n",
    "                if labels_map[idx] == 'fake':\n",
    "                    fake_prob += prob\n",
    "                    real_prob += 1-prob\n",
    "                else:\n",
    "                    real_prob += prob\n",
    "                    fake_prob += 1 - prob\n",
    "        if real_prob > fake_prob:\n",
    "            predictions[vid.split('/')[-2]] = 1\n",
    "            probs[vid.split('/')[-2]] = (real_prob/len(images))\n",
    "#             print(image)\n",
    "#             print('real', real_prob/len(images))\n",
    "        else:\n",
    "            predictions[vid.split('/')[-2]] = 0\n",
    "            probs[vid.split('/')[-2]] = 1-(fake_prob/len(images))\n",
    "#             print(image)\n",
    "#             print('fake', fake_prob/len(images))\n",
    "    else:\n",
    "        pass\n",
    "    print('--------------')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dffbd4",
   "metadata": {},
   "source": [
    "# Write results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea976bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = ('TestScores/Image/dfdc/no_augs/')\n",
    "# with open(folder_path + model_name + '_' + 'results.csv', 'w') as csvfile:\n",
    "#     fieldnames = ['Epoch', 'Train Accuracy', 'Train Loss', 'Validation Accuracy', 'Validation Loss']\n",
    "#     writer = csv.DictWriter(csvfile, fieldnames=fieldnames, lineterminator='\\n',)\n",
    "\n",
    "#     writer.writeheader()\n",
    "#     for i in range(len(validation_accuracies)):\n",
    "#         writer.writerow({'Epoch': i+1, 'Train Accuracy': round(train_accuracies[i].item(), 4), 'Train Loss': round(train_losses[i].item(), 4), 'Validation Accuracy': round(validation_accuracies[i].item(), 4), 'Validation Loss': round(validation_losses[i].item(), 4)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639febfa",
   "metadata": {},
   "source": [
    "# Model Parameter Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28727aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['xception', 'res2net101_26w_4s', 'tf_efficientnet_b7_ns', 'vit_base_patch16_224', 'swin_base_patch4_window7_224', 'xcit_medium_24_p16_224', 'cait_s24_224']\n",
    "\n",
    "net = timm.create_model(models[6], pretrained=True, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9db13b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XCEPTION\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "round(pytorch_total_params/1000000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76734cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Res2Net 101\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "round(pytorch_total_params/1000000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa79b77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Efficient Net B7\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "round(pytorch_total_params/1000000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39ea390f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ViT Base\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "round(pytorch_total_params/1000000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8e655c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swin Base\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "round(pytorch_total_params/1000000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39f5b866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XCIT Medium\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "round(pytorch_total_params/1000000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2bb2db8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CAIT S\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "round(pytorch_total_params/1000000, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17705dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = sorted(glob.glob('../Datasets/DeepfakeDetection/FakeAVCeleb_v1_2/Cleaned_Data/Images/test_set_fake/*/'))\n",
    "videos = [path.replace('\\\\','/') for path in videos]\n",
    "\n",
    "len(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21df54bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "new_valid_list_real = []\n",
    "for i in range(len(videos)):\n",
    "    frames_in_video = sorted(glob.glob(videos[i] +'/*.png'))\n",
    "    if len(frames_in_video) < 20:\n",
    "        count+=1\n",
    "        print(videos[i])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d861522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
